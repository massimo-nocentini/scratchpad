{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some gotchas\n",
    "\n",
    "The following notebook collect some cell to understand -- the hard way -- little, but *subtle*, concepts.\n",
    "\n",
    "The main reference from which they are taken is the book by [Magnus Lie Hetland][hetland], in pure [Python][py].\n",
    "\n",
    "[hetland]:http://hetland.org/writing/python-algorithms/\n",
    "[py]:http://www.python.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python's `list.append` isn't Lisp's `cons`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python `list` objects behave like `stack` objects, such that it is *cheap* to `append` and `pop` at the *top*, which is the *right* end. On the other hand, Lisp `pair` objects allows us to *easily* `cons` on the *beginning*, the very *opposite* direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fast_countdown(count):\n",
    "    nums = []\n",
    "    for i in range(count):\n",
    "        nums.append(i)\n",
    "    nums.reverse()\n",
    "    return nums\n",
    "\n",
    "def slow_countdown(count):\n",
    "    nums = []\n",
    "    for i in range(count):\n",
    "        nums.insert(0, i)\n",
    "    return nums\n",
    "\n",
    "def printer(lst, chunk=10):\n",
    "    print(\"{}...{}\".format(\" \".join(map(str, lst[:chunk])),\n",
    "                           \" \".join(map(str, lst[-chunk:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.84 ms per loop\n",
      "99999 99998 99997 99996 99995 99994 99993 99992 99991 99990...9 8 7 6 5 4 3 2 1 0\n"
     ]
    }
   ],
   "source": [
    "%timeit nums = fast_countdown(10**5)\n",
    "printer(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.86 s per loop\n",
      "99999 99998 99997 99996 99995 99994 99993 99992 99991 99990...9 8 7 6 5 4 3 2 1 0\n"
     ]
    }
   ],
   "source": [
    "%timeit nums = slow_countdown(10**5)\n",
    "printer(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citing Hetland, pag 11:\n",
    "\n",
    "> Python lists aren’t really lists in the traditional computer science sense of the word, and that explains the puzzle of why append is so much more efficient than insert . A classical list - a so-called linked list - is implemented as a series of nodes, each (except for the last) keeping a reference to the next. \n",
    "The underlying implementation of Python’s list type is a bit different. Instead of several separate nodes\n",
    "referencing each other, a list is basically a single, contiguous slab of memory - what is usually known as an\n",
    "array. This leads to some important differences from linked lists. For example, while iterating over the contents\n",
    "of the list is equally efficient for both kinds (except for some overhead in the linked list), directly accessing an element at a given index is much more efficient in an array. This is because the position of the element can be\n",
    "calculated, and the right memory location can be accessed directly. In a linked list, however, one would have to\n",
    "traverse the list from the beginning.\n",
    "The difference we've been bumping up against, though, has to do with insertion. In a linked list, once you know\n",
    "where you want to insert something, insertion is cheap; it takes roughly the same amount of time, no matter how\n",
    "many elements the list contains. That's not the case with arrays: An insertion would have to move all elements\n",
    "that are to the right of the insertion point, possibly even moving all the elements to a larger array, if needed.\n",
    "A specific solution for appending is to use what’s often called a dynamic array, or vector. 4 The idea is to allocate an array that is too big and then to reallocate it in linear time whenever it overflows. It might seem that this makes the append just as bad as the insert. In both cases, we risk having to move a large number of elements.\n",
    "The main difference is that it happens less often with the append. In fact, if we can ensure that we always move\n",
    "to an array that is bigger than the last by a fixed percentage (say 20 percent or even 100 percent), the average\n",
    "cost, amortized over many appends, is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enhance with `deque` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`deque` implements *FIFO* queues: they are as cheap to append to the right as a normal `list`, but enhance it to *cheaply* insert on the *front* too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def enhanced_slow_countdown(count):\n",
    "    nums = deque()\n",
    "    for i in range(count):\n",
    "        nums.appendleft(i)\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 8.22 ms per loop\n",
      "99999 99998 99997 99996 99995 99994 99993 99992 99991 99990...9 8 7 6 5 4 3 2 1 0\n"
     ]
    }
   ],
   "source": [
    "%timeit nums = enhanced_slow_countdown(10**5)\n",
    "printer(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concerning `list`s and `set`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "max_value = 10000\n",
    "checks = 1000\n",
    "L = [randrange(max_value) for i in range(checks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 18 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit [randrange(max_value) in L for _ in range(checks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.11 ms per loop\n"
     ]
    }
   ],
   "source": [
    "S = set(L)\n",
    "\n",
    "%timeit [randrange(max_value) in S for _ in range(checks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hetland's words, pag. 35:\n",
    "\n",
    ">They're both pretty fast, and it might seem pointless to create a set from the list—unnecessary work, right? Well,\n",
    "it depends. If you're going to do many membership checks, it might pay off, because membership checks are linear\n",
    "for lists and constant for sets. What if, for example, you were to gradually add values to a collection and for each step check whether the value was already added? [...] Using a list would give you quadratic running time, whereas using a set would be linear. That’s a huge difference. **The lesson is that it's important to pick the right built-in data structure for the job.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists = [[1, 2], [3, 4, 5], [6]]\n",
    "sum(lists, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hetland, pag.36:\n",
    "\n",
    ">This works, and it even looks rather elegant, but it really isn't. You see, under the covers, the sum function doesn't know all too much about what you’re summing, and it has to do one addition after another. That way, you're right back at the quadratic running time of the += example for strings. Here's a better way: Just try timing both versions. As long as lists is pretty short, there won't be much difference, but it shouldn't\n",
    "take long before the sum version is thoroughly beaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for lst in lists:\n",
    "    res.extend(lst)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concerning `string`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def string_producer(length=10**7):\n",
    "    return ''.join([chr(randrange(ord('a'), ord('z'))) for _ in range(length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 14.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit # %% means 'cell-wise'\n",
    "\n",
    "s = \"\"\n",
    "for chunk in string_producer():\n",
    "    s += chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe some optimization is performed because `s` is a `string` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 14.7 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "chunks = []\n",
    "for chunk in string_producer():\n",
    "    chunks.append(chunk)\n",
    "s = ''.join(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a better approach using constant `append` to the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 14.2 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit s = ''.join(string_producer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe a little better since it doesn't loop with `for` explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max permutation\n",
    "\n",
    "The following function `max_perm` computes the maximum permutation that can be applied given a desired one; namely,\n",
    "it produces a new permutation that moves as many elements as it can, in order to ensure the `one-to-one` property. It can be seen as a function that *fixes* a given permutation according to the required behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_max_perm(M, A=None):\n",
    "    '''\n",
    "    Fix a permutation such that it is one-to-one and maximal, recursively.\n",
    "    \n",
    "    consumes:\n",
    "    M - a permutation as a list of integers\n",
    "    A - a set of positions allowed to move\n",
    "    \n",
    "    produces:\n",
    "    a set `fix` such that makes M maximal, ensuring to be one-to-one\n",
    "    '''\n",
    "    if A is None: A = set(range(len(M))) # init to handle first invocation, all elems can move\n",
    "    \n",
    "    if len(A) is 1: return A # recursion base, unary perm can move, trivial\n",
    "    \n",
    "    B = set(M[i] for i in A) # b in B iff b is desired by someone\n",
    "    C = A - B # c in C iff c isn't desired, so discard it\n",
    "    return naive_max_perm(M, A - C) if C else A # recur with desired position only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity = range(8)\n",
    "letters = \"abcdefgh\"\n",
    "perm_isomorphism(identity, letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'c', 'a', 'f', 'd', 'e', 'h', 'e']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [2, 2, 0, 5, 3, 4, 7, 4]\n",
    "perm_isomorphism(M, letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'b', 'a', 'f', 'd', 'e', 'g', 'h']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix = naive_max_perm(M)\n",
    "max_M = fix_perm(M, fix)\n",
    "perm_isomorphism(max_M, letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hetland, pag. 78:\n",
    "\n",
    ">The function naive_max_perm receives a set `A` of remaining people and creates a set `B` of seats that are pointed\n",
    "to. If it finds an element in `A` that is not in `B`, it removes the element and solves the remaining problem recursively. Let's use the implementation on our example, M = `[2, 2, 0, 5, 3, 5, 7, 4]`:\n",
    " \n",
    "    naive_max_perm(M)\n",
    "    {0, 2, 5}\n",
    " \n",
    ">So, a, c, and f can take part in the permutation. The others will have to sit in nonfavorite seats.\n",
    "The implementation isn't too bad. The handy set type lets us manipulate sets with ready-made high-level operations,\n",
    "rather than having to implement them ourselves. There are some problems, though. For one thing, we might want an\n",
    "iterative solution. [...] A worse problem, though, is that the algorithm is quadratic! (Exercise 4-10 asks you to show this.) The most wasteful operation is the repeated creation of the set B. If we could just keep track of which chairs are no longer pointed to, we could eliminate this operation entirely. One way of doing this would be to keep a count for each element. We could decrement the count for chair x when a person pointing to x is eliminated, and if x ever got a count of zero, both person and chair x would be out of the game.\n",
    ">>This idea of reference counting can be useful in general. It is, for example, a basic component in many systems\n",
    "for garbage collection (a form of memory management that automatically deallocates objects that are no longer useful). You'll see this technique again in the discussion of topological sorting.\n",
    "\n",
    ">There may be more than one element to be eliminated at any one time, but we can just put any new ones we\n",
    "come across into a “to-do” list and deal with them later. If we needed to make sure the elements were eliminated in\n",
    "the order in which we discover that they’re no longer useful, we would need to use a first-in, first-out queue such as the deque class (discussed in Chapter 5). We don’t really care, so we could use a set, for example, but just appending to and popping from a list will probably give us quite a bit less overhead. But feel free to experiment, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def max_perm(M):\n",
    "    n = len(M) # How many elements?\n",
    "    A = set(range(n)) # A = {0, 1, ... , n-1}\n",
    "    count = Counter(M) # desired positions by frequencies\n",
    "    Q = deque([i for i in A if not count[i]]) # useless elements\n",
    "    while Q: # While useless elts. left...\n",
    "        i = Q.pop() # get one of them\n",
    "        A.remove(i) # remove it from the maximal permutation\n",
    "        j = M[i] # get its desired position\n",
    "        count[j] -= 1 # and release it for someone else\n",
    "        if not count[j]: # if such position isn't desired anymore\n",
    "            Q.appendleft(j) # enqueue such position in order to discard it            \n",
    "    return A\n",
    "\n",
    "def fix_perm(M, fix):\n",
    "    return [M[i] if i in fix else i for i in range(len(M))]\n",
    "\n",
    "def perm_isomorphism(M, domain):\n",
    "    iso = dict(enumerate(domain))\n",
    "    return [iso[M[i]] for i in range(len(M))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'b', 'a', 'f', 'd', 'e', 'g', 'h']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix = max_perm(M)\n",
    "max_M = fix_perm(M, fix)\n",
    "perm_isomorphism(max_M, letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8773687304994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{8773687304994: 'hello'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "o = object()\n",
    "print(hash(o))\n",
    "d[hash(o)]='hello'\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
